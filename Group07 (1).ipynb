{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40a10d35001d11f819d8dae50b2083bf",
     "grade": false,
     "grade_id": "cell-ee16a386069c0891",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Read This First\n",
    "\n",
    "* You will provide a single Jupyter notebook file.\n",
    "* Each function should have appropriate documentation in the form of a docstring and in-line comments. \n",
    "* Each code explanation (i.e. Part 3 for each Section) should be written in markdown. \n",
    "* You can use any built-in Python functions (those that don't need libraries) and any libraries *used in the labs* (i.e., those following some `import` statement). No other libraries are allowed.\n",
    "\n",
    "**You *will* be penalised if you don't follow these instructions.**\n",
    "\n",
    "## Background information\n",
    "\n",
    "*In which you will write a tool to advice people to avoid some unnecessary line changes in the London Underground.*\n",
    "\n",
    "File `underground.zip` contains thirteen text files. File `station_names.csv` is a CSV file where each row is a pair containing an arbitrary *station id* and the *name* of a station in the London Underground. File `walking_times.csv` is a CSV file where each row contains a pair of station ids and the time to walking between the corresponding stations. Note that this does not contain all pairs of stations. CSV files such as `UG_bakerloo.csv` represent the connectivity at different lines in the Underground (e.g., the Bakerloo line). Each row contains a pair of station ids that indicate that such stations are adjacent to each other in that particular line. For instance, the first line in `UG_bakerloo.csv` is `11,135`, indicating that station id 11 (Baker Street) and station id 135 (Marylebone) are next to each other in the Bakerloo line.\n",
    "\n",
    "All sorts of network analyses can be done in a system like the London Underground. For instance, we may wish to know whether we can easily avoid changing lines for a particular journey: say I'm outside Marylebone and I want to go to Euston Square. I could enter the Underground in Marylebone, change at Baker Street, and then go to Euston Square. But Baker Street is just a short walk from Marylebone. If I happen to know that, I may wish to just walk there and start my Underground journey from Baker Street. This provides motivation to Section B below.\n",
    "\n",
    "You may wish to check out the official [London Underground map](https://tfl.gov.uk/maps/track/tube) to better understand the data, but please bear in mind that the files in `underground.zip` are not up to date, and minor differences are to be expected. \n",
    "\n",
    "## Section A: Data Wrangling\n",
    "\n",
    "Your overall task here is to combine the information from a number of csv files into a single pandas DataFrame. \n",
    "\n",
    "### Part 1\n",
    "\n",
    "Write a function to be called `load_underground_data`. It takes as input a string `path_name` and loads to memory the station names in `station_names.csv`, the walking times in `walking_times.csv`, and each of the lines `UG_*.csv`. You should combine the lines data into a single DataFrame, named `tube_lines`, containing three colums: the first column should be the name of the line, as a user-friendly string, while the last two columns should be the station ids of the adjacent stations. For example, for the first line in `UG_bakerloo.csv`, i.e. `11,135`, the corresponding row in `tube_lines` should be `'Bakerloo',11,135`.\n",
    "\n",
    "The output of `load_underground_data` should be three DataFrames: `station_names`, `walking_times`, and `tube_lines`, in that order.\n",
    "\n",
    "**Hints and reminders**\n",
    "\n",
    "Note that the `walking_times.csv` file contains a header row, while the others do not. Be careful with how you set the column names!\n",
    "\n",
    "You can make a Python function return any number of outputs if you separate them by commas. For instance `return a, b` will return two outputs, `a` and `b`, simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4062a3a5fd0a8764b9ed03212bf42def",
     "grade": false,
     "grade_id": "cell-56a65e502db59941",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "\n",
    "def load_underground_data(path_name):\n",
    "    '''\n",
    "    this function takes in path_name and loads underground csv files into their respective dataframes\n",
    "    '''\n",
    "    station_names = pd.read_csv(\"station_names.csv\", names=[\"id\", \"name\"], header=None)\n",
    "    # creates dataframe for the station names\n",
    "    walking_times = pd.read_csv(\"walking_times.csv\")\n",
    "    # creates dataframe for the walking times\n",
    "\n",
    "    UG_lines = [\"bakerloo\", \"central\", \"circle\", \"district\", \"hammersmith_city\", \"jubilee\",\n",
    "                \"metropolitan\", \"northern\", \"piccadilly\", \"victoria\", \"waterloo_city\"]\n",
    "    # creates list of underground lines to help create tube_lines dataframes\n",
    "\n",
    "    tube_lines = []  # this will be the list of all tube lines and their available stations\n",
    "    for line in UG_lines:\n",
    "        # loops through each underground line, reads the corresponding csv file,\n",
    "        # and appends to a larger dataframe for all tube lines\n",
    "        df = pd.read_csv(f\"UG_{line}.csv\", names=[\"previous_station_id\", \"next_station_id\"], header=None)\n",
    "        df['line'] = line.title()\n",
    "        tube_lines.append(df)\n",
    "    tube_lines = pd.concat(tube_lines, ignore_index=True)\n",
    "    tube_lines = tube_lines[['line', 'previous_station_id', 'next_station_id']]\n",
    "\n",
    "    return station_names, walking_times, tube_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2c8bb9b1b279ed40132b00cdad96a2fe",
     "grade": true,
     "grade_id": "cell-fde7a4c3337c2376",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      id                name\n",
       " 0      1          Acton Town\n",
       " 1      2            Barbican\n",
       " 2      3             Aldgate\n",
       " 3      4        Aldgate East\n",
       " 4      5            Alperton\n",
       " ..   ...                 ...\n",
       " 264  265      West Hampstead\n",
       " 265  266  Willesden Junction\n",
       " 266  267            Richmond\n",
       " 267  268           Wimbledon\n",
       " 268  269           Upminster\n",
       " \n",
       " [269 rows x 2 columns],\n",
       "                      A                  B  Walking Time\n",
       " 0    Elephant & Castle      Lambeth North            18\n",
       " 1        Lambeth North           Waterloo             9\n",
       " 2             Waterloo         Embankment             6\n",
       " 3           Embankment      Charing Cross             3\n",
       " 4        Charing Cross  Piccadilly Circus            11\n",
       " ..                 ...                ...           ...\n",
       " 206      Finsbury Park      Seven Sisters            38\n",
       " 207      Seven Sisters     Tottenham Hale            19\n",
       " 208     Tottenham Hale    Blackhorse Road            18\n",
       " 209    Blackhorse Road        Walthamstow            24\n",
       " 210           Waterloo               Bank            33\n",
       " \n",
       " [211 rows x 3 columns],\n",
       "               line  previous_station_id  next_station_id\n",
       " 0         Bakerloo                   11              135\n",
       " 1         Bakerloo                   11              175\n",
       " 2         Bakerloo                   39              216\n",
       " 3         Bakerloo                   39              229\n",
       " 4         Bakerloo                   66              122\n",
       " ..             ...                  ...              ...\n",
       " 359       Victoria                  202              253\n",
       " 360       Victoria                  202              254\n",
       " 361       Victoria                  224              252\n",
       " 362       Victoria                  252              253\n",
       " 363  Waterloo_City                   13              229\n",
       " \n",
       " [364 rows x 3 columns])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your code here\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "MY_PATH = \"/Users/sahmrahman/Desktop/STAT0040/underground\"\n",
    "os.chdir(MY_PATH)\n",
    "load_underground_data(MY_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "328e957f280735e903c93dc2f6be89f6",
     "grade": true,
     "grade_id": "cell-4d13e16cdafa3cd9",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LEAVE THIS CELL BLANK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6bbcc458c2701e926c1786b0f3a3af0e",
     "grade": false,
     "grade_id": "cell-0a530648999c054a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Part 2\n",
    "\n",
    "Write a function that combines each of the datasets into a single pandas DataFrame. Your output should have six columns, with each row corresponding to a single row in one of the `UG_*.csv` files. The columns should include the name of the line, the ID of the first station, the ID of the second station, the name of the first station, the name of the second station, and the walking time between the two stations (or NaN if this data is not available in `walking_times.csv`).\n",
    "\n",
    "**Hints**\n",
    "\n",
    "Note that there are slight discrepancies in how the stations are named between some of the files. In particular, the punctuation used in the names are different between `station_names.csv` and `walking_times.csv`. You may find the `pd.Series.str.replace` method helpful. \n",
    "\n",
    "Note that the order of pairs of stations may not necessarily be the same between `walking_times.csv` and the `UG_*.csv` files. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2ce402249d8ff8de9de26d5d9155237c",
     "grade": false,
     "grade_id": "cell-6c1d58434712dcfc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def combine_underground_data(station_names, walking_times, tube_lines):\n",
    "    '''\n",
    "    takes in the three DataFrame objects, combines into one large DataFrame, and another smaller DataFrame of \n",
    "    walking times that do not belong to any common lines\n",
    "    these two DataFrames are returned together in a tuple\n",
    "    '''\n",
    "\n",
    "    # fixes punctuation discrepancies\n",
    "    walking_times['A'] = walking_times['A'].str.replace(\"'\", '')\n",
    "    walking_times['A'] = walking_times['A'].str.replace(\".\", '')\n",
    "    walking_times['B'] = walking_times['B'].str.replace(\"'\", '')\n",
    "    walking_times['B'] = walking_times['B'].str.replace(\".\", '')\n",
    "\n",
    "    # merge walking times and IDs, separately from station names and IDs\n",
    "    # allows for us to keep walking times that don't belong to a line\n",
    "    walking_and_first_ID = walking_times.merge(station_names,\n",
    "                                               left_on='A',\n",
    "                                               right_on='name',\n",
    "                                               how='left')\n",
    "    walking_and_first_ID['id'] = walking_and_first_ID['id'].astype(int)\n",
    "\n",
    "    walking_and_IDs = walking_and_first_ID.merge(station_names,\n",
    "                                                 left_on='B',\n",
    "                                                 right_on='name',\n",
    "                                                 how='left')\n",
    "\n",
    "    names_and_first_ID = tube_lines.merge(station_names,\n",
    "                                          left_on='previous_station_id',\n",
    "                                          right_on='id',\n",
    "                                          how='left')\n",
    "\n",
    "    names_and_IDs = names_and_first_ID.merge(station_names,\n",
    "                                             left_on='next_station_id',\n",
    "                                             right_on = 'id',\n",
    "                                             how='left')\n",
    "\n",
    "    fully_combined = names_and_IDs.merge(walking_and_IDs,\n",
    "                                         left_on=['name_x', 'name_y'],\n",
    "                                         right_on=['A', 'B'],\n",
    "                                         how='outer')\n",
    "\n",
    "\n",
    "    # separate rows with walking times that belong to a line and those without\n",
    "    \n",
    "    walking_and_lines = fully_combined[0:364]\n",
    "    walking_without_lines = fully_combined[364:]\n",
    "    \n",
    "    # reformat the dataframes\n",
    "\n",
    "    walking_and_lines = walking_and_lines.drop(['id_x_x', 'id_y_x', 'A', 'B', 'id_x_y', 'name_x_y', 'id_y_y', 'name_y_y'], axis=1)\n",
    "    walking_and_lines.rename(columns={\n",
    "        'line': 'Underground Line',\n",
    "        'previous_station_id': 'First Station ID',\n",
    "        'next_station_id': 'Second Station ID',\n",
    "        'name_x_x': 'First Station Name',\n",
    "        'name_y_x': 'Second Station Name',\n",
    "        'Walking Time': 'Walking Time (mins)',\n",
    "\n",
    "    }, inplace=True)\n",
    "    walking_and_lines['First Station ID'] = walking_and_lines['First Station ID'].astype(int)\n",
    "    walking_and_lines['Second Station ID'] = walking_and_lines['Second Station ID'].astype(int)\n",
    "\n",
    "    walking_without_lines = walking_without_lines.drop([\n",
    "        'line',\n",
    "        'previous_station_id',\n",
    "        'next_station_id',\n",
    "        'id_x_x',\n",
    "        'name_x_x',\n",
    "        'id_y_x',\n",
    "        'name_y_x',\n",
    "        'name_x_y',\n",
    "        'name_y_y'\n",
    "    ], axis=1)\n",
    "\n",
    "    walking_without_lines = walking_without_lines[walking_without_lines.columns[[3, 4, 0, 1, 2]]]\n",
    "    walking_without_lines['id_x_y'] = walking_without_lines['id_x_y'].astype(int)\n",
    "    walking_without_lines['id_y_y'] = walking_without_lines['id_y_y'].astype(int)\n",
    "    walking_without_lines.rename(columns={\n",
    "        'id_x_y': 'First Station ID',\n",
    "        'id_y_y': 'Second Station ID',\n",
    "        'Walking Time': 'Walking Time (mins)'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    return walking_and_lines, walking_without_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a429dc4c094e309406f18be6b022246e",
     "grade": true,
     "grade_id": "cell-e77e89b8717c89c9",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Underground Line  First Station ID  Second Station ID First Station Name  \\\n",
      "0           Bakerloo                11                135       Baker Street   \n",
      "1           Bakerloo                11                175       Baker Street   \n",
      "2           Bakerloo                39                216         Embankment   \n",
      "3           Northern                39                216         Embankment   \n",
      "4           Bakerloo                39                229         Embankment   \n",
      "..               ...               ...                ...                ...   \n",
      "359         Victoria               202                253          Stockwell   \n",
      "360         Victoria               202                254          Stockwell   \n",
      "361         Victoria               224                252           Victoria   \n",
      "362         Victoria               252                253            Pimlico   \n",
      "363    Waterloo_City                13                229               Bank   \n",
      "\n",
      "    Second Station Name  Walking Time (mins)  \n",
      "0            Marylebone                  6.0  \n",
      "1          Regents Park                  NaN  \n",
      "2         Charing Cross                  3.0  \n",
      "3         Charing Cross                  3.0  \n",
      "4              Waterloo                  6.0  \n",
      "..                  ...                  ...  \n",
      "359            Vauxhall                  NaN  \n",
      "360             Brixton                 16.0  \n",
      "361             Pimlico                 12.0  \n",
      "362            Vauxhall                 18.0  \n",
      "363            Waterloo                  NaN  \n",
      "\n",
      "[364 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/01/2v7vs_955yj7l2gpbc2ntr7m0000gn/T/ipykernel_58430/620981787.py:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  walking_times['A'] = walking_times['A'].str.replace(\".\", '')\n",
      "/var/folders/01/2v7vs_955yj7l2gpbc2ntr7m0000gn/T/ipykernel_58430/620981787.py:12: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  walking_times['B'] = walking_times['B'].str.replace(\".\", '')\n"
     ]
    }
   ],
   "source": [
    "# Test your code here\n",
    "data_frames = load_underground_data(MY_PATH)\n",
    "print(combine_underground_data(data_frames[0], data_frames[1], data_frames[2])[0])\n",
    "# this will only return the rows with walking times assigned to a line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0ec843a81b99bed20dc090289c3e0cd",
     "grade": true,
     "grade_id": "cell-f3229ae223d9995b",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LEAVE THIS CELL BLANK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa8ffe6d0e934267a9ea61af350ea091",
     "grade": false,
     "grade_id": "cell-d49d979226a4da14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Part 3\n",
    "\n",
    "Write a short Markdown paragraph explaining your code in Parts 1 and 2. Your answer should be 4-6 sentences long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fb1d08dc41cf9408038bfa12abb922c1",
     "grade": true,
     "grade_id": "cell-0360576f41c895dc",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "Part 1 creates three `DataFrame` objects for `station_names.csv`, `walking_times.csv`, and all `UG_*.csv` files given in the underground zip/folder using pandas' `read_csv()` function. By looping through each `UG_*.csv` file and appending its contents to one `DataFrame` object, `tube_lines` is created to hold all underground lines and their respective stations. \n",
    "\n",
    "Part 2 combines the three `DataFrame` objects (`station_names`, `walking_times`, and `tube_lines`) and returns the result as two `DataFrame` objects: one with walking times that run along underground lines, and ones that do not. This is achieved using the `merge()` function. We rearrange and reformat the two `DataFrame`s to be easier to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "018e0abb65759fc299c5cb270d7f144c",
     "grade": false,
     "grade_id": "cell-88a08c61add610f0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Section B\n",
    "\n",
    "The aim of this section is to write a function to provide directions from one station to another, where it may be possible to begin the journey with a walk.\n",
    "\n",
    "### Part 1a\n",
    "\n",
    "Write a function called `get_connections`. This function should take as input the combined DataFrame that you output from `combine_underground_data`. It should return a dictionary of eleven `ndarray` objects. These should correspond to the eleven tube lines. Each `ndarray` must be a square matrix of integers (any type of integer is fine) with the number of rows and columns given by the total number of stations. Entries in any of the `ndarray` objects are equal to 0 if the corresponding stations are not adjacent in that line, and 1 if they are adjacent. Station positions must be coherent with `station_names`. For instance, entry `connections[0][134, 10]` (as well as `[10, 134]`) will be set to 1 assuming `134` corresponds to Marylebone, and `10` corresponds to Baker Street (remember that Python indexing starts from 0, so those station numbers should not be `135` and `11`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab59ab07a04a3565bbaaa6bc1e326eff",
     "grade": false,
     "grade_id": "cell-0f1acfb1a9cf7b0f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_connections(combined_data):\n",
    "    '''\n",
    "    Takes in combined dataframe to put stations into a dictionary \n",
    "    of underground lines mapped to a 269x269 array of their repsective connections\n",
    "    '''\n",
    "    connections = {}  # created a dictionary for the connections for each line\n",
    "    station_names = pd.read_csv(\"station_names.csv\", names=[\"id\", \"name\"], header=None)\n",
    "\n",
    "    # Gets the 11 underground lines from the combined Dataframe\n",
    "    UG_lines = [\"Bakerloo\", \"Central\", \"Circle\", \"District\", \"Hammersmith_City\", \"Jubilee\",\n",
    "                \"Metropolitan\", \"Northern\", \"Piccadilly\", \"Victoria\", \"Waterloo_City\"]\n",
    "\n",
    "    # Used the for loop to iterate through the underground lines to get the inidividual lines\n",
    "    for line in UG_lines:\n",
    "\n",
    "        # Created an empty NumPy array for the connections in the line\n",
    "        connections[line] = np.zeros((len(station_names), len(station_names)), dtype=int)\n",
    "\n",
    "        # Used the for loop to iterate through the rows to get the ID of the stations\n",
    "        for i, j in combined_data[combined_data[\"Underground Line\"] == line].iterrows():  # i,j=column,row\n",
    "\n",
    "            # Gets the ID of the 1st station and the 2nd station\n",
    "            # station_id_1 = int(j['First Station ID'][not math.isnan(j['First Station ID'])])\n",
    "            # station_id_2 = int(j['Second Station ID'][not math.isnan(j['Second Station ID'])])\n",
    "            station_id_1 = j['First Station ID']\n",
    "            station_id_2 = j['Second Station ID']\n",
    "\n",
    "            # Sets the connection between the two stations to 1\n",
    "            connections[line][station_id_1 - 1][station_id_2 - 1] = 1\n",
    "            connections[line][station_id_2 - 1][station_id_1 - 1] = 1\n",
    "\n",
    "    return connections\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e7d4d54fcf265d170149f7bb6632e8a",
     "grade": true,
     "grade_id": "cell-fa36098bb96011db",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/01/2v7vs_955yj7l2gpbc2ntr7m0000gn/T/ipykernel_58430/1900729762.py:8: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  walking_times['A'] = walking_times['A'].str.replace(\".\", '')\n",
      "/var/folders/01/2v7vs_955yj7l2gpbc2ntr7m0000gn/T/ipykernel_58430/1900729762.py:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  walking_times['B'] = walking_times['B'].str.replace(\".\", '')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Bakerloo': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'Central': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'Circle': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'District': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'Hammersmith_City': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'Jubilee': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'Metropolitan': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'Northern': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'Piccadilly': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'Victoria': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " 'Waterloo_City': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your code here\n",
    "data_frames = load_underground_data(MY_PATH)\n",
    "combined_data=combine_underground_data(data_frames[0], data_frames[1], data_frames[2])[0]\n",
    "# combined_data is a tuple of the two dataframes (walking along lines, walking without common lines)\n",
    "get_connections(combined_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0ae955e4a375bee0f0c29c79012ec9ce",
     "grade": false,
     "grade_id": "cell-93ee354f5e0f3a8d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Part 1b\n",
    "\n",
    "Write a function called `get_walking_net`.  This function should take as input the combined DataFrame that you output from `combine_underground_data`, and should return a single nunmpy `ndarray` object containing the walking times between stations. If the walking time between two stations is not contained in the `walking_times.csv` file, then the corresponding entry in the `ndarray` should be NaN. As in Part 1a, the station positions must be coherent with `station_names`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "66d4b7cc3fcb520325ba0618f8c7ea46",
     "grade": false,
     "grade_id": "cell-6c7c053cc0b44753",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_walking_net(combined_data_and_strays):\n",
    "    station_names = pd.read_csv(\"station_names.csv\", names=[\"id\", \"name\"], header=None)\n",
    "\n",
    "    # Created an empty array for the walking times between the stations\n",
    "    walking_net = np.empty((len(station_names), len(station_names)), dtype=float)\n",
    "    walking_net[:] = np.nan\n",
    "\n",
    "    # Used the for loop to iterate through the rows to get the ID of the stations and the walking times between these\n",
    "    # stations\n",
    "    for i, j in combined_data_and_strays[0].iterrows():  # i,j=column,row\n",
    "\n",
    "        # station_id_1 = int(j['First Station ID'][not math.isnan(['First Station ID'])])  # Gets id of 1st station\n",
    "        # station_id_2 = int(j['Second Station ID'][not math.isnan(j['Second Station ID'])])  # Gets id of 2nd station\n",
    "        station_id_1 = j['First Station ID']\n",
    "        station_id_2 = j['Second Station ID']\n",
    "        walking_time = j['Walking Time (mins)']  # Gets the walking time between the two stations\n",
    "\n",
    "        # Gives the walking time between both station 1 and station 2\n",
    "        walking_net[station_id_1 - 1][station_id_2 - 1] = walking_time\n",
    "        walking_net[station_id_2 - 1][station_id_1 - 1] = walking_time\n",
    "\n",
    "    for i, j in combined_data_and_strays[1].iterrows(): # do the same with our stray walking times\n",
    "        station_id_1 = j['First Station ID']\n",
    "        station_id_2 = j['Second Station ID']\n",
    "        walking_time = j['Walking Time (mins)']  \n",
    "\n",
    "        walking_net[station_id_1 - 1][station_id_2 - 1] = walking_time\n",
    "        walking_net[station_id_2 - 1][station_id_1 - 1] = walking_time\n",
    "\n",
    "\n",
    "    return walking_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "558c87dca406f0abd20f2a317d487233",
     "grade": true,
     "grade_id": "cell-2675f50e37aa7963",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/01/2v7vs_955yj7l2gpbc2ntr7m0000gn/T/ipykernel_58430/1900729762.py:8: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  walking_times['A'] = walking_times['A'].str.replace(\".\", '')\n",
      "/var/folders/01/2v7vs_955yj7l2gpbc2ntr7m0000gn/T/ipykernel_58430/1900729762.py:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  walking_times['B'] = walking_times['B'].str.replace(\".\", '')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your code here\n",
    "data_frames = load_underground_data(MY_PATH)\n",
    "combined_data=combine_underground_data(data_frames[0], data_frames[1], data_frames[2])\n",
    "get_walking_net(combined_data)\n",
    "# get_walking_net() takes in both elements of the combined_data tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ee9cae2e5afcf362d1624ae55f3e8d57",
     "grade": true,
     "grade_id": "cell-c7ed86635f519856",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LEAVE THIS CELL BLANK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "67ea6b6b9b000283ad57a404ee975e64",
     "grade": false,
     "grade_id": "cell-d98d2d40429ea7d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Part 2\n",
    "\n",
    "Write a function to be called `single_change_adviser`. It takes as input two integers, `station_in` and `station_out`. It also takes as input a dictionary of `ndarrays` to be called `connections`, assumed to come from a call to `get_connections`, and a single `ndarray` of walking times, assumed to come from a call to `get_walking_net`. Each of `station_in`, `station_out` is assumed to correspond to a station position as in `station_names`. This function must return one of these three outputs:\n",
    "\n",
    "* if there is a common Underground line that contains both `station_in` and `station_out`, return the *tuple* `(station_in, line, 0)`, where `line` is the common Underground line (as named in `connections`);\n",
    "* if `station_out` is not in any common line with `station_in`, but `station_in` is walkable to a connecting station (let's call its number `station_change`) that *is* in a same line as `station_out`, then return the tuple `(station_change, line, walking_time)`, where `line` is the common line of `station_change` and `station_out`, and `walking_time` is the time it takes to walk from `station_in` to `station_change`;\n",
    "* if none of the above applies, return the tuple `(None, None, None)`;\n",
    "\n",
    "If more than one solution applies (say, `station_in` and `station_out` share more than one common line), just return one possible solution using any criteria of your choice.\n",
    "\n",
    "**Hints and Reminders**\n",
    "\n",
    "You can check whether a station is in a particular Underground line by checking whether it has any non-zero entries in the respective row/column of `connections`. You can use whatever *NumPy* commands you wish to make your life here as easy as possible. Examples of useful *NumPy* functions are given in particular in Labs 5-7.\n",
    "\n",
    "A tuple is just a type of list that we can't change once we create it, and the notation uses round brackets instead of square brackets (e.g. `[\"hello\", \"world!\"]` is a list while `(\"hello\", \"world!\")` is a tuple).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "16595649f2bc740a6889dcc651859d15",
     "grade": false,
     "grade_id": "cell-a2311d610d76e70f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_IDs(connection_grids, line):\n",
    "    '''\n",
    "    returns all station IDs on line as a 1-dimensional array\n",
    "    '''\n",
    "    stations = []\n",
    "    for row in range(269):\n",
    "        for col in range(269):\n",
    "            if connection_grids[line][row][col] == 1:\n",
    "                stations.append(row + 1)\n",
    "                stations.append(col + 1)\n",
    "    return stations\n",
    "\n",
    "\n",
    "def single_change_adviser(station_in, station_out, connections, walking_net):\n",
    "    '''\n",
    "    returns first available route betweens station_in and station_out\n",
    "    route is either direct, interchange, or walking change\n",
    "    '''\n",
    "    # checks for common line for the station_in and station_out\n",
    "    for line in connections.keys():\n",
    "        direct_stations = get_IDs(connections, line)\n",
    "        if direct_stations.__contains__(station_in) and direct_stations.__contains__(station_out):\n",
    "            # DIRECT ROUTE\n",
    "            return (station_in, line, 0)\n",
    "\n",
    "    # Checks if there are no common lines, but checks if there is a station that is the same line as\n",
    "    # station_out and that is in a walkable distance to station_in\n",
    "\n",
    "    for line in connections.keys():\n",
    "        # redo the direct_stations\n",
    "        # this is necessary in practice because without separating the for loops, it is possible\n",
    "        # a route with one change is given instead of a direct route\n",
    "        direct_stations = get_IDs(connections, line)\n",
    "        if not direct_stations.__contains__(station_in):\n",
    "            continue\n",
    "        for second_line in connections.keys():\n",
    "            if line == second_line:  # it is possible when loop through the lines twice we are checking the same line\n",
    "                # in that case, we will of course find similarities in the lines stations since they are all equal\n",
    "                # this case is useless, so we skip over it\n",
    "                continue\n",
    "            change_stations = get_IDs(connections, second_line)\n",
    "            if not change_stations.__contains__(station_out):\n",
    "                continue\n",
    "            for potential_change in direct_stations:  # loop through all stations in line\n",
    "                for potential_change_other_line in change_stations:  # loop through all stations in line_\n",
    "                    if potential_change == potential_change_other_line:\n",
    "                        # we found a match in stations between different lines... not sure if i need this ^^ part\n",
    "                        # INTERCHANGE ROUTE\n",
    "                        return (potential_change, second_line, 0)\n",
    "                    if not math.isnan(walking_net[potential_change - 1][potential_change_other_line - 1]) \\\n",
    "                            and direct_stations.__contains__(potential_change) \\\n",
    "                            and change_stations.__contains__(potential_change_other_line):\n",
    "                        # we have two lines with two stations that share a walking time\n",
    "                        # WALKING CHANGE ROUTE\n",
    "                        return (potential_change_other_line, second_line,\n",
    "                                walking_net[potential_change - 1][potential_change_other_line - 1])\n",
    "\n",
    "    return (None, None, None)\n",
    "        \n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b190a89e7974ed08442cb570e651791f",
     "grade": true,
     "grade_id": "cell-d41b23a97af02690",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 'Piccadilly', 14.0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your code here\n",
    "station_in=134\n",
    "station_out=106\n",
    "connections=get_connections(combined_data[0])\n",
    "walking_net=get_walking_net(combined_data)\n",
    "single_change_adviser(station_in, station_out, connections, walking_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ef930948aa92ccdd8e92fcc299125001",
     "grade": true,
     "grade_id": "cell-dc4d1c77cb5a2c91",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LEAVE THIS CELL BLANK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "73e786a972133a7d34100ea5efb556ca",
     "grade": false,
     "grade_id": "cell-a506888561688e91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Part 3\n",
    "\n",
    "Write an explanation of how your code for Section B works. Your answer should be 4-6 sentences long."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40aa99bda67c427873e7172e4884408d",
     "grade": true,
     "grade_id": "cell-00715e5d68f7a6e5",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "To create our connections map, we initialise an empty dictionary which will be populated with Underground line names for its keys and the respective 269x269 numpy ndarray for its values. To create our walking net, we initialise a 269x269 numpy ndarray of nan values. Both are populated by extracting the appropriate values from our combined DataFrames. \n",
    "\n",
    "We created a function called get_IDs that takes in any line and the connections map, and it returns an array of all station IDs on that line by looping through each 269x269 ndarray in each Underground line. \n",
    "\n",
    "single_change_advisor will take in the stations in and out, the connections map, and walking net. This function will return the first available route it finds (either direct, interchange, or walking change). It does so by using get_IDs on our stations in and out and checks for common stations both on the same line or different lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0a3fc172908e6d43b81de1b835635f5e",
     "grade": false,
     "grade_id": "cell-8b2b492f9f22d5e5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "## Section C: OOP\n",
    "\n",
    "*In which you will discuss how OOP can be applied to your previous solution.*\n",
    "\n",
    "We will now apply an object-oriented programming (OOP) perspective to the code written Sections A and B. Please keep everything simple, much of the following consists of reusing code from the previous Sections. **The less you add to it, the better.**\n",
    "\n",
    "\n",
    "### Part 1 \n",
    "Create a class `Underground` that will encapsulate data loading and station change advice as originally implemented in Sections A and B. It should provide access to its internal data using *Python properties* only (as in Exercise 3 of Lab 8). Write the code necessary for that in any way you find sensible.\n",
    "\n",
    "**Reminder**\n",
    "\n",
    "Several other examples of Python properties are given in the solutions to the exercises of Lab 8, it's not only Exercise 3 which uses them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b974ad115343b010e308a3b8e08381e3",
     "grade": false,
     "grade_id": "cell-07a2cf601f0f0ec9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Underground:\n",
    "    def __init__(self, path_name):\n",
    "        '''\n",
    "        creates Underground object using path_name to Underground csv files\n",
    "        '''\n",
    "\n",
    "        # gather info\n",
    "        data_frames_ = load_underground_data(path_name)\n",
    "        combined_data_ = combine_underground_data(data_frames_[0], data_frames_[1], data_frames_[2])\n",
    "        self.connection_grids = get_connections(combined_data_[0])\n",
    "        self.walking_net = get_walking_net(combined_data_)\n",
    "\n",
    "        # conversions\n",
    "        for line in self.connection_grids.keys():\n",
    "            self.connection_grids[line] = self.connection_grids[line].tolist()\n",
    "        self.walking_net = self.walking_net.tolist()\n",
    "\n",
    "    def _get_IDs(self, connection_grids, line):\n",
    "        '''\n",
    "        returns all station IDs on line as a 1-dimensional array\n",
    "        '''\n",
    "        stations = []\n",
    "        for row in range(269):\n",
    "            for col in range(269):\n",
    "                if connection_grids[line][row][col] == 1:\n",
    "                    stations.append(row + 1)\n",
    "                    stations.append(col + 1)\n",
    "        return stations\n",
    "\n",
    "    def single_change_adviser(self, station_in_ID, station_out_ID):\n",
    "        '''\n",
    "        returns first available route betweens station_in and station_out\n",
    "        route is either direct, interchange, or walking change\n",
    "        '''\n",
    "        # checks for common line for the station_in and station_out\n",
    "\n",
    "        for line in self.connection_grids.keys():\n",
    "\n",
    "            direct_stations = self._get_IDs(self.connection_grids, line)\n",
    "            if direct_stations.__contains__(station_in_ID) and direct_stations.__contains__(station_out_ID):\n",
    "                # DIRECT ROUTE\n",
    "                return (station_in_ID, line, 0)\n",
    "\n",
    "            # Checks if there are no common lines, but checks if there is a station that is the same line as\n",
    "            # station_out and that is in a walkable distance to station_in\n",
    "\n",
    "        for line in self.connection_grids.keys():\n",
    "\n",
    "            # redo the direct_stations\n",
    "            # this is necessary in practice because without separating the for loops, it is possible\n",
    "            # a route with one change is given instead of a direct route\n",
    "\n",
    "            direct_stations = self._get_IDs(self.connection_grids, line)\n",
    "            if not direct_stations.__contains__(station_in_ID):\n",
    "                continue\n",
    "\n",
    "            for second_line in self.connection_grids.keys():\n",
    "                if line == second_line:\n",
    "                    # it is possible when loop through the lines twice we are checking the same line\n",
    "                    # in that case, we will of course find similarities in the lines stations since they are all equal\n",
    "                    # this case is useless, so we skip over it\n",
    "                    continue\n",
    "\n",
    "                change_stations = self._get_IDs(self.connection_grids, second_line)\n",
    "                if not change_stations.__contains__(station_out_ID):\n",
    "                    continue\n",
    "\n",
    "                for potential_change in direct_stations:  # loop through all stations in line\n",
    "\n",
    "                    for potential_change_other_line in change_stations:  # loop through all stations in line_\n",
    "\n",
    "                        if potential_change == potential_change_other_line and potential_change_other_line != station_in_ID:\n",
    "                            # we found a match in stations between different lines... not sure if i need this ^^ part\n",
    "                            # INTERCHANGE ROUTE\n",
    "                            return (potential_change, second_line, 0)\n",
    "\n",
    "                        if not math.isnan(self.walking_net[potential_change - 1][potential_change_other_line - 1]) \\\n",
    "                                and direct_stations.__contains__(potential_change) \\\n",
    "                                and change_stations.__contains__(potential_change_other_line):\n",
    "                            # we have two lines with two stations that share a walking time\n",
    "                            # WALKING CHANGE ROUTE\n",
    "                            return (potential_change_other_line, second_line,\n",
    "                                    self.walking_net[potential_change - 1][potential_change_other_line - 1])\n",
    "\n",
    "        return (None, None, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7d842e510c97e1e16e9ee339dd2ba78",
     "grade": true,
     "grade_id": "cell-fb43365358d069bd",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 'Piccadilly', 14.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/01/2v7vs_955yj7l2gpbc2ntr7m0000gn/T/ipykernel_58430/1900729762.py:8: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  walking_times['A'] = walking_times['A'].str.replace(\".\", '')\n",
      "/var/folders/01/2v7vs_955yj7l2gpbc2ntr7m0000gn/T/ipykernel_58430/1900729762.py:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  walking_times['B'] = walking_times['B'].str.replace(\".\", '')\n"
     ]
    }
   ],
   "source": [
    "# Test your code here\n",
    "\n",
    "ug = Underground(MY_PATH)\n",
    "print(ug.single_change_adviser(134, 106))\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5e534ed1345a65a78938958a68326d1e",
     "grade": true,
     "grade_id": "cell-46ccc664e38bd2f4",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LEAVE THIS CELL BLANK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1533dca2aad07d147f0735d065a180ca",
     "grade": false,
     "grade_id": "cell-b4a23567fa5d7a69",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "\n",
    "### Part 2\n",
    "\n",
    "Write an alternative version of `Underground` where the  internal implementation of `connections` is done similarly to the implementation of `adjacencies` of the `Network` class of Lab 9 (the main point being implementing the adjacencies as dictionaries instead of `ndarrays`). You must keep the public method names and arguments as presented in the implementation of Part 1. As in the `Network` example of Lab 9, you must create a new class representing stations, and another class representing links between physically adjacent Underground stations. Keep those classes as simple as possible. There is no need to create new methods to add individual vertices and edges, all vertices and edges can be added when loading the data. In fact, there is no need for any new public methods in the modified `Underground` class at all.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "254e1dde6d6cb7cc715d0d9020e2832a",
     "grade": false,
     "grade_id": "cell-f85da41e78e62d84",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Station:  # Station is the vertex\n",
    "    def __init__(self, id):\n",
    "        ''' \n",
    "        Creating station Id objects by ID\n",
    "        '''\n",
    "        self._id = id\n",
    "        # self._name = name\n",
    "\n",
    "\n",
    "class Line: # Line is the edge\n",
    "    def __init__(self, name):\n",
    "        '''\n",
    "        Creating line objects by name\n",
    "        '''\n",
    "        self.name = name\n",
    "\n",
    "\n",
    "class Network:\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Creating an empty set for the stations and an empty dictionary for the adjacent stations to their respective stations\n",
    "        '''\n",
    "        self._stations = set()\n",
    "        self._adjacencies = dict()\n",
    "\n",
    "    def add_stations(self, station):\n",
    "        '''\n",
    "        Add stations to the set\n",
    "        Adds to adjacent station to the empty dictionary\n",
    "        '''\n",
    "        self._stations.add(station)\n",
    "        self._adjacencies[station] = []\n",
    "\n",
    "    def add_edge(self, station_1: Station, station_2: Station, edge: Line):\n",
    "        '''\n",
    "        Add edges to the vertices which are the adjacent stations on the same line\n",
    "        '''\n",
    "        self._adjacencies[station_1].append((station_2, edge))\n",
    "\n",
    "\n",
    "class Underground:  # load data\n",
    "\n",
    "    def __init__(self, path_name):\n",
    "        '''\n",
    "        creates Underground object using path_name to Underground csv files\n",
    "        '''\n",
    "\n",
    "        # gather info\n",
    "        data_frames_ = load_underground_data(path_name)\n",
    "        combined_data_ = combine_underground_data(data_frames_[0], data_frames_[1], data_frames_[2])\n",
    "        self.connection_grids = get_connections(combined_data_[0])\n",
    "        self.walking_net = get_walking_net(combined_data_)\n",
    "\n",
    "        net = Network()\n",
    "\n",
    "        stations = [None] * 269\n",
    "\n",
    "        for i in range(len(stations)):\n",
    "            stations[i] = Station(i + 1)\n",
    "\n",
    "        for j in stations:\n",
    "            net.add_stations(j)\n",
    "\n",
    "        self.tube_lines = [\"Bakerloo\", \"Central\", \"Circle\", \"District\", \"Hammersmith_City\", \"Jubilee\",\n",
    "                           \"Metropolitan\", \"Northern\", \"Piccadilly\", \"Victoria\", \"Waterloo_City\"]\n",
    "\n",
    "        self.UG_stations = {}\n",
    "        for line in self.tube_lines:\n",
    "            self.UG_stations[line] = []\n",
    "\n",
    "        for line in self.connection_grids.keys():\n",
    "            for row in range(269):\n",
    "                for col in range(269):\n",
    "                    if self.connection_grids[line][row][col] == 1:\n",
    "                        net.add_edge(stations[row], stations[col], Line(line))\n",
    "                        net.add_edge(stations[col], stations[row], Line(line))\n",
    "\n",
    "                        self.UG_stations[line].append(row+1)\n",
    "                        self.UG_stations[line].append(col+1)\n",
    "\n",
    "\n",
    "        self.connection_grids = net\n",
    "\n",
    "    def get_combined_data(self):\n",
    "        '''\n",
    "        Gets the combined data\n",
    "        '''\n",
    "        return combined_data_\n",
    "\n",
    "    def single_change_adviser(self, station_in_ID, station_out_ID):\n",
    "        '''\n",
    "        returns first available route betweens station_in and station_out\n",
    "        route is either direct, interchange, or walking change\n",
    "        '''\n",
    "        # checks for common line for the station_in and station_out\n",
    "\n",
    "        for line in self.tube_lines:\n",
    "\n",
    "            direct_stations = self.UG_stations[line]\n",
    "            if direct_stations.__contains__(station_in_ID) and direct_stations.__contains__(station_out_ID):\n",
    "                # DIRECT ROUTE\n",
    "                return (station_in_ID, line, 0)\n",
    "\n",
    "            # Checks if there are no common lines, but checks if there is a station that is the same line as\n",
    "            # station_out and that is in a walkable distance to station_in\n",
    "\n",
    "        for line in self.tube_lines:\n",
    "\n",
    "            # redo the direct_stations\n",
    "            # this is necessary in practice because without separating the for loops, it is possible\n",
    "            # a route with one change is given instead of a direct route\n",
    "\n",
    "            direct_stations = self.UG_stations[line]\n",
    "            if not direct_stations.__contains__(station_in_ID):\n",
    "                continue\n",
    "\n",
    "            for second_line in self.tube_lines:\n",
    "                if line == second_line:\n",
    "                    # it is possible when loop through the lines twice we are checking the same line\n",
    "                    # in that case, we will of course find similarities in the lines stations since they are all equal\n",
    "                    # this case is useless, so we skip over it\n",
    "                    continue\n",
    "\n",
    "                change_stations = self.UG_stations[second_line]\n",
    "                if not change_stations.__contains__(station_out_ID):\n",
    "                    continue\n",
    "\n",
    "                for potential_change in direct_stations:  # loop through all stations in line\n",
    "\n",
    "                    for potential_change_other_line in change_stations:  # loop through all stations in line_\n",
    "\n",
    "                        if potential_change == potential_change_other_line and potential_change_other_line != station_in_ID:\n",
    "                            # we found a match in stations between different lines... not sure if i need this ^^ part\n",
    "                            # INTERCHANGE ROUTE\n",
    "                            return (potential_change, second_line, 0)\n",
    "\n",
    "                        if not math.isnan(self.walking_net[potential_change - 1][potential_change_other_line - 1]) \\\n",
    "                                and direct_stations.__contains__(potential_change) \\\n",
    "                                and change_stations.__contains__(potential_change_other_line):\n",
    "                            # we have two lines with two stations that share a walking time\n",
    "                            # WALKING CHANGE ROUTE\n",
    "                            return (potential_change_other_line, second_line,\n",
    "                                    self.walking_net[potential_change - 1][potential_change_other_line - 1])\n",
    "\n",
    "        return (None, None, None)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03d0e35af3059008174e3a695fa7a454",
     "grade": true,
     "grade_id": "cell-ad1cf35d5a9ee2c8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/01/2v7vs_955yj7l2gpbc2ntr7m0000gn/T/ipykernel_58430/1900729762.py:8: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  walking_times['A'] = walking_times['A'].str.replace(\".\", '')\n",
      "/var/folders/01/2v7vs_955yj7l2gpbc2ntr7m0000gn/T/ipykernel_58430/1900729762.py:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  walking_times['B'] = walking_times['B'].str.replace(\".\", '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 'Piccadilly', 14.0)\n"
     ]
    }
   ],
   "source": [
    "# Test your code here\n",
    "ug_test = Underground(MY_PATH)\n",
    "print(ug_test.single_change_adviser(134, 106))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a8dceb366cc1f9055735b097df44fc06",
     "grade": true,
     "grade_id": "cell-d3a5d588487076ae",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LEAVE THIS CELL BLANK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a12860923da72669c553c910a1693d76",
     "grade": false,
     "grade_id": "cell-6ba4f653b4b6df47",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Part 3\n",
    "\n",
    "Write a short discussion (4-6 sentences) about how you think OOP is useful in the two cases above, explaining how you made your choices on how to organise your code. *Without writing any code*, explain a very simple example on how you could extend either the `Underground` or the corresponding vertex/edge classes to add functionality to your code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6847e90078f77a0017944e286fadf0c5",
     "grade": true,
     "grade_id": "cell-306b43bd9ba88b94",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "The OOP is useful for the first case as it encapsulates data such as the walking times and connections and methods which are unique to the Underground class. The OOP is useful for the second case as it allowed us to add new functions and new objects to create lists such as adjacency list of the conncections between the stations. We could extend the Underground classes by producing a method called Djikstra's algorithm which calculates the shortest route between 2 stations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e0a73c4fecc7317041e7e87ab2798c5b",
     "grade": false,
     "grade_id": "cell-037b1d4ae1ad3764",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "### Part 4\n",
    "\n",
    "Write a simple unit test function to test the method `single_change_adviser`. Your test function should implement at least three test cases. This function should work for both implementations of the `Underground` class in Part 1 and Part 2, behaving exactly the same regardless of which version is the one being used.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "292dbf51be8321aaddf8a9bd4f4471d6",
     "grade": true,
     "grade_id": "cell-73f75c05f9db6f6e",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def test_single_change_adviser():\n",
    "    '''\n",
    "    runs pre-generated test runs of single_change_adviser\n",
    "    three unique scenarios are run in which there is either a direct, interchange or walking connection\n",
    "    '''\n",
    "    ug_test = Underground(MY_PATH)\n",
    "    #Test case 1 - Direct route\n",
    "    #Liverpol street-128 and bond street-23\n",
    "    if ug_test.single_change_adviser(128, 23)==(128,\"Central\",0):\n",
    "        print(\"Test 1 works - Take the Central Line straight from Liverpool street to Bond street\")\n",
    "        \n",
    "    #Test case 2 - Route with 1 change \n",
    "    #Marble Arch-134, Green Park-85 and Hounslow Central-106\n",
    "    if ug_test.single_change_adviser(134, 106)==(85,\"Piccadilly\",14.0):\n",
    "        print(\"Test 2 works - Walk 14 minutes from Marble Arch to Green Park and take the Piccadilly line to Hounslow Central\")\n",
    "    \n",
    "    #Test case 3 - Walking change route  \n",
    "    #Heahtrow 123-256, Finsbury Park-75, Arsenal-10 and seven sisters-186\n",
    "    if ug_test.single_change_adviser(256, 186)==(75,\"Victoria\",10.0):\n",
    "        print(\"Test 3 works - Take the Picadilly Line from Heathrow 123 to Arsenal, then walk 10 minutes to Finsbury Park and then take the victoria line to seven sisters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c40217b693eb932a0d678e095552f6f5",
     "grade": true,
     "grade_id": "cell-697b18bdaea264b6",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/01/2v7vs_955yj7l2gpbc2ntr7m0000gn/T/ipykernel_58430/969052575.py:7: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  walking_times['A'] = walking_times['A'].str.replace(\".\", '')\n",
      "/var/folders/01/2v7vs_955yj7l2gpbc2ntr7m0000gn/T/ipykernel_58430/969052575.py:9: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  walking_times['B'] = walking_times['B'].str.replace(\".\", '')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 works - Take the Central Line straight from Liverpool street to Bond street\n",
      "Test 2 works - Walk 14 minutes from Marble Arch to Green Park and take the Piccadilly line to Hounslow Central\n",
      "Test 3 works - Take the Picadilly Line from Heathrow 123 to Arsenal, then walk 10 minutes to Finsbury Park and then take the victoria line to seven sisters\n"
     ]
    }
   ],
   "source": [
    "# Test your code here\n",
    "test_single_change_adviser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
